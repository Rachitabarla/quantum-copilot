{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "import pandas as pd\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from pydantic import BaseModel\n",
    "from langchain.chat_models import ChatOpenAI \n",
    "from langchain.text_splitter import SpacyTextSplitter\n",
    "from dotenv import load_dotenv\n",
    "import pdb\n",
    "#import tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\",temperature=0)\n",
    "embeddings = OpenAIEmbeddings(deployment=\"embeddings model\", chunk_size=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(pdf):\n",
    "    ''' This utility is used to convert the pdfs into chunks of texts '''\n",
    "    #loader = PyPDFLoader(pdf)\n",
    "    loader = TextLoader(pdf,encoding='MacRoman')\n",
    "    documents = loader.load()\n",
    "\n",
    "    text_splitter = CharacterTextSplitter(chunk_size = 900, chunk_overlap = 200)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    return texts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 2179, which is longer than the specified 900\n",
      "Created a chunk of size 17770, which is longer than the specified 900\n",
      "Created a chunk of size 6607, which is longer than the specified 900\n",
      "Created a chunk of size 3418, which is longer than the specified 900\n",
      "Created a chunk of size 36950, which is longer than the specified 900\n",
      "Created a chunk of size 1393, which is longer than the specified 900\n",
      "Created a chunk of size 13512, which is longer than the specified 900\n",
      "Created a chunk of size 70175, which is longer than the specified 900\n",
      "Created a chunk of size 12164, which is longer than the specified 900\n",
      "Created a chunk of size 15614, which is longer than the specified 900\n",
      "Created a chunk of size 1792, which is longer than the specified 900\n",
      "Created a chunk of size 1077, which is longer than the specified 900\n",
      "Created a chunk of size 1023, which is longer than the specified 900\n",
      "Created a chunk of size 1556, which is longer than the specified 900\n",
      "Created a chunk of size 16322, which is longer than the specified 900\n",
      "Created a chunk of size 2496, which is longer than the specified 900\n",
      "Created a chunk of size 1062, which is longer than the specified 900\n",
      "Created a chunk of size 1921, which is longer than the specified 900\n",
      "Created a chunk of size 1081, which is longer than the specified 900\n",
      "Created a chunk of size 916, which is longer than the specified 900\n",
      "Created a chunk of size 1085, which is longer than the specified 900\n",
      "Created a chunk of size 977, which is longer than the specified 900\n",
      "Created a chunk of size 915, which is longer than the specified 900\n",
      "Created a chunk of size 985, which is longer than the specified 900\n",
      "Created a chunk of size 1275, which is longer than the specified 900\n",
      "Created a chunk of size 980, which is longer than the specified 900\n",
      "Created a chunk of size 2154, which is longer than the specified 900\n",
      "Created a chunk of size 1139, which is longer than the specified 900\n",
      "Created a chunk of size 2367, which is longer than the specified 900\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Could not import tiktoken python package. This is needed in order to for OpenAIEmbeddings. Please install it with `pip install tiktoken`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\embeddings\\openai.py:268\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[1;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 268\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtiktoken\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tiktoken'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m pdf_text \u001b[38;5;241m=\u001b[39m load_pdf(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../files/(1) Master Paper - Ultrafast quantum random number generation using quantum phase fluctuations.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m doc_search_pdf \u001b[38;5;241m=\u001b[39m \u001b[43mFAISS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m doc_search_pdf\u001b[38;5;241m.\u001b[39msave_local(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./fiass_db/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuantum Computing.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\vectorstores\\base.py:332\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[1;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[0;32m    330\u001b[0m texts \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m    331\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m--> 332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_texts(texts, embedding, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\vectorstores\\faiss.py:551\u001b[0m, in \u001b[0;36mFAISS.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    526\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_texts\u001b[39m(\n\u001b[0;32m    527\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    533\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FAISS:\n\u001b[0;32m    534\u001b[0m     \u001b[38;5;124;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \n\u001b[0;32m    536\u001b[0m \u001b[38;5;124;03m    This is a user friendly interface that:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    549\u001b[0m \u001b[38;5;124;03m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 551\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    552\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__from(\n\u001b[0;32m    553\u001b[0m         texts,\n\u001b[0;32m    554\u001b[0m         embeddings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    559\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\embeddings\\openai.py:452\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[1;34m(self, texts, chunk_size)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;124;03m\"\"\"Call out to OpenAI's embedding endpoint for embedding search docs.\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \n\u001b[0;32m    442\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[1;32m--> 452\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeployment\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\embeddings\\openai.py:270\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[1;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtiktoken\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m--> 270\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    271\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import tiktoken python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    272\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is needed in order to for OpenAIEmbeddings. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    273\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install tiktoken`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    274\u001b[0m     )\n\u001b[0;32m    276\u001b[0m tokens \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    277\u001b[0m indices \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mImportError\u001b[0m: Could not import tiktoken python package. This is needed in order to for OpenAIEmbeddings. Please install it with `pip install tiktoken`."
     ]
    }
   ],
   "source": [
    "pdf_text = load_pdf(\"../files/(1) Master Paper - Ultrafast quantum random number generation using quantum phase fluctuations.pdf\")\n",
    "doc_search_pdf = FAISS.from_documents(pdf_text, embeddings)\n",
    "doc_search_pdf.save_local(\"./fiass_db/\"+\"Quantum Computing.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import faiss python package. Please install it with `pip install faiss` or `pip install faiss-cpu` (depending on Python version).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\vectorstores\\faiss.py:38\u001b[0m, in \u001b[0;36mdependable_faiss_import\u001b[1;34m(no_avx2)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m         \u001b[39mimport\u001b[39;00m \u001b[39mfaiss\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'faiss'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\quantum-copilot\\src\\app.ipynb Cell 6\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/quantum-copilot/src/app.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m persisted_vectorstore \u001b[39m=\u001b[39m FAISS\u001b[39m.\u001b[39;49mload_local(\u001b[39m\"\u001b[39;49m\u001b[39m./fiass_db/\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mQuantum Computing.pdf\u001b[39;49m\u001b[39m\"\u001b[39;49m, embeddings)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/quantum-copilot/src/app.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m# Use RetrievalQA chain for orchestration\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/quantum-copilot/src/app.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m qa \u001b[39m=\u001b[39m RetrievalQA\u001b[39m.\u001b[39mfrom_chain_type(llm\u001b[39m=\u001b[39mllm, chain_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstuff\u001b[39m\u001b[39m\"\u001b[39m, retriever\u001b[39m=\u001b[39mpersisted_vectorstore\u001b[39m.\u001b[39mas_retriever())\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\vectorstores\\faiss.py:635\u001b[0m, in \u001b[0;36mFAISS.load_local\u001b[1;34m(cls, folder_path, embeddings, index_name)\u001b[0m\n\u001b[0;32m    633\u001b[0m path \u001b[39m=\u001b[39m Path(folder_path)\n\u001b[0;32m    634\u001b[0m \u001b[39m# load index separately since it is not picklable\u001b[39;00m\n\u001b[1;32m--> 635\u001b[0m faiss \u001b[39m=\u001b[39m dependable_faiss_import()\n\u001b[0;32m    636\u001b[0m index \u001b[39m=\u001b[39m faiss\u001b[39m.\u001b[39mread_index(\n\u001b[0;32m    637\u001b[0m     \u001b[39mstr\u001b[39m(path \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m{index_name}\u001b[39;00m\u001b[39m.faiss\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(index_name\u001b[39m=\u001b[39mindex_name))\n\u001b[0;32m    638\u001b[0m )\n\u001b[0;32m    640\u001b[0m \u001b[39m# load docstore and index_to_docstore_id\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\vectorstores\\faiss.py:40\u001b[0m, in \u001b[0;36mdependable_faiss_import\u001b[1;34m(no_avx2)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[39mimport\u001b[39;00m \u001b[39mfaiss\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m---> 40\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m     41\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCould not import faiss python package. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     42\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease install it with `pip install faiss` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     43\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor `pip install faiss-cpu` (depending on Python version).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     44\u001b[0m     )\n\u001b[0;32m     45\u001b[0m \u001b[39mreturn\u001b[39;00m faiss\n",
      "\u001b[1;31mImportError\u001b[0m: Could not import faiss python package. Please install it with `pip install faiss` or `pip install faiss-cpu` (depending on Python version)."
     ]
    }
   ],
   "source": [
    "persisted_vectorstore = FAISS.load_local(\"./fiass_db/\"+\"Quantum Computing.pdf\", embeddings)\n",
    "\n",
    "    # Use RetrievalQA chain for orchestration\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=persisted_vectorstore.as_retriever())\n",
    "result = qa.run(\"What is Quantum Computing\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_pdf(query):\n",
    "    # Load document using PyPDFLoader document loader\n",
    "    loader = PyPDFLoader(\"Downloads/Quantum Computing.pdf\")\n",
    "    documents = loader.load()\n",
    "    # Split document in chunks\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=30, separator=\"\\n\")\n",
    "    docs = text_splitter.split_documents(documents=documents)\n",
    "\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    # Create vectors\n",
    "    vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "    # Persist the vectors locally on disk\n",
    "    vectorstore.save_local(\"faiss_index_constitution\")\n",
    "\n",
    "    # Load from local storage\n",
    "    persisted_vectorstore = FAISS.load_local(\"faiss_index_constitution\", embeddings)\n",
    "\n",
    "    # Use RetrievalQA chain for orchestration\n",
    "    qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=persisted_vectorstore.as_retriever())\n",
    "    result = qa.run(query)\n",
    "    print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    query = input(\"Type in your query: \\n\")\n",
    "    while query != \"exit\":\n",
    "        query_pdf(query)\n",
    "        query = input(\"Type in your query: \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "pypdf package not found, please install it with `pip install pypdf`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\document_loaders\\pdf.py:108\u001b[0m, in \u001b[0;36mPyPDFLoader.__init__\u001b[1;34m(self, file_path, password)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 108\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mpypdf\u001b[39;00m  \u001b[39m# noqa:F401\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pypdf'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\quantum-copilot\\src\\app.ipynb Cell 9\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/quantum-copilot/src/app.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m main()\n",
      "\u001b[1;32md:\\quantum-copilot\\src\\app.ipynb Cell 9\u001b[0m line \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/quantum-copilot/src/app.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m query \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mType in your query: \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/quantum-copilot/src/app.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mwhile\u001b[39;00m query \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mexit\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/quantum-copilot/src/app.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     query_pdf(query)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/quantum-copilot/src/app.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     query \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mType in your query: \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32md:\\quantum-copilot\\src\\app.ipynb Cell 9\u001b[0m line \u001b[0;36mquery_pdf\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/quantum-copilot/src/app.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mquery_pdf\u001b[39m(query):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/quantum-copilot/src/app.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m# Load document using PyPDFLoader document loader\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/quantum-copilot/src/app.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     loader \u001b[39m=\u001b[39m PyPDFLoader(\u001b[39m\"\u001b[39;49m\u001b[39mDownloads/Quantum Computing.pdf\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/quantum-copilot/src/app.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     documents \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39mload()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/quantum-copilot/src/app.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# Split document in chunks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\document_loaders\\pdf.py:110\u001b[0m, in \u001b[0;36mPyPDFLoader.__init__\u001b[1;34m(self, file_path, password)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mpypdf\u001b[39;00m  \u001b[39m# noqa:F401\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m--> 110\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m    111\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpypdf package not found, please install it with \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m`pip install pypdf`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    112\u001b[0m     )\n\u001b[0;32m    113\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparser \u001b[39m=\u001b[39m PyPDFParser(password\u001b[39m=\u001b[39mpassword)\n\u001b[0;32m    114\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(file_path)\n",
      "\u001b[1;31mImportError\u001b[0m: pypdf package not found, please install it with `pip install pypdf`"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
